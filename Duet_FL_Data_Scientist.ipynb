{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earlier-investing",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 1 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sized-session",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "â™«â™«â™« > Duet Client ID: \u001b[1m1912f0cdf422d82a117b09ba86f59080\u001b[0m\n",
      "\n",
      "â™«â™«â™« > ...waiting for partner to connect...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "C:\\Users\\dylan\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet1 = sy.duet(\"ff666f18ef6e671b4e03d545833f2134\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-container",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 2 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-knife",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "â™«â™«â™« > Duet Client ID: \u001b[1mf8ac1de9f28c439b56b7ba642f91d424\u001b[0m\n",
      "\n",
      "â™«â™«â™« > ...waiting for partner to connect...\n",
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet2 = sy.duet(\"bd2681f95556591e6687b3935c7a0412\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wanted-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 322b7b11d20b44faa2a0c61e97a921d2&gt;</td>\n",
       "      <td>[DO1 training X data]</td>\n",
       "      <td>number of samples and features</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: f1f767cee96e45d88c16552acf7cf02a&gt;</td>\n",
       "      <td>[DO1 training y data]</td>\n",
       "      <td>number of samples and features</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID                   Tags  \\\n",
       "0  <UID: 322b7b11d20b44faa2a0c61e97a921d2>  [DO1 training X data]   \n",
       "1  <UID: f1f767cee96e45d88c16552acf7cf02a>  [DO1 training y data]   \n",
       "\n",
       "                      Description             object_type  \n",
       "0  number of samples and features  <class 'torch.Tensor'>  \n",
       "1  number of samples and features  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet1.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "going-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 0702fd696c874562a96199fcaf09a96b&gt;</td>\n",
       "      <td>[DO2 training X data]</td>\n",
       "      <td>number of samples and features</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: a5244cc8ac964d08a03b8ea7433f6374&gt;</td>\n",
       "      <td>[DO2 training y data]</td>\n",
       "      <td>number of samples and features</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID                   Tags  \\\n",
       "0  <UID: 0702fd696c874562a96199fcaf09a96b>  [DO2 training X data]   \n",
       "1  <UID: a5244cc8ac964d08a03b8ea7433f6374>  [DO2 training y data]   \n",
       "\n",
       "                      Description             object_type  \n",
       "0  number of samples and features  <class 'torch.Tensor'>  \n",
       "1  number of samples and features  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet2.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-cradle",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qualified-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x00000231B2F8AB50>\n",
      "<syft.proxy.torch.TensorPointer object at 0x00000231B3546A60>\n",
      "<syft.proxy.torch.TensorPointer object at 0x00000231B35468B0>\n",
      "<syft.proxy.torch.TensorPointer object at 0x00000231B35467C0>\n"
     ]
    }
   ],
   "source": [
    "data1_ptr = duet1.store[0]\n",
    "target1_ptr = duet1.store[1]\n",
    "data2_ptr = duet2.store[0]\n",
    "target2_ptr = duet2.store[1]\n",
    "\n",
    "print(data1_ptr)\n",
    "print(target1_ptr)\n",
    "print(data2_ptr)\n",
    "print(target2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-savage",
   "metadata": {},
   "source": [
    "### Create Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bizarre-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn \n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_poisson_deviance\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advised-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_dim = 39\n",
    "#out_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sapphire-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class SyNet(sy.Module):\n",
    "    #def __init__(self, torch_ref):\n",
    "        #super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        #self.linear = self.torch_ref.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    #def forward(self, x):\n",
    "        #x = self.linear(x)\n",
    "        #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9f02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        \n",
    "        self.layer_1 = self.torch_ref.nn.Linear(39, 31)\n",
    "        self.layer_out = self.torch_ref.nn.Linear(31, 1)\n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout_1 = self.torch_ref.nn.Dropout(0.12409392594394411)\n",
    "        self.relu = self.torch_ref.nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.dropout_1(self.relu(self.layer_1(inputs)))\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return (x)\n",
    "\n",
    "    def predict(self, test_inputs):\n",
    "        x = self.relu(self.layer_1(test_inputs))\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-factor",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def5a92",
   "metadata": {},
   "source": [
    "Try training loop from MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2799b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MNIST(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((train_data_length / args[\"batch_size\"]) + 0.5)\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    if model.is_local:\n",
    "        print(\"Training requires remote model\")\n",
    "        return\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = torch_ref.nn.functional.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = duet.python.Float(0)  # create a remote Float we can use for summation\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            local_loss = None\n",
    "            local_loss = loss_item.get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5\n",
    "            )\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break\n",
    "        if args[\"dry_run\"]:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d0eca44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "#train_data_ptr = duet1.store[0]\n",
    "train_loader_ptr = remote_torch1.utils.data.DataLoader(data1_ptr,**train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "077158a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally we would not necessarily know the length of a remote dataset so lets ask for it\n",
    "# so we can pass that to our training loop and know when to stop\n",
    "def get_train_length(train_data_ptr):\n",
    "    train_data_length = len(train_data_ptr)\n",
    "    return train_data_length\n",
    "\n",
    "try:\n",
    "    if train_data_length is None:\n",
    "        train_data_length = get_train_length(data1_ptr)\n",
    "except NameError:\n",
    "        train_data_length = get_train_length(data1_ptr)\n",
    "\n",
    "print(f\"Training Dataset size is: {train_data_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chinese-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    #criterion = torch_ref.nn.functional.poisson_nll_loss(log_input= True, full= True)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data_ptr)\n",
    "\n",
    "        #loss = torch_ref.nn.functional.nll_loss(output, target_ptr)\n",
    "        loss = torch_ref.nn.functional.poisson_nll_loss(output, target_ptr, log_input= True, full= True)   \n",
    "        #loss = torch_ref.nn.functional.mse_loss(output, target_ptr)\n",
    "        #loss = criterion(output, target_ptr)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\",\n",
    "            request_block=True,\n",
    "            timeout_secs=5,\n",
    "        )\n",
    "\n",
    "        print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-guide",
   "metadata": {},
   "source": [
    "#### Send one copy of the model to each data owner or client and train them remotely one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "virgin-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee21bc",
   "metadata": {},
   "source": [
    "Create a local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proved-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-partner",
   "metadata": {},
   "source": [
    "Send the model to DO1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "convinced-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1 = base_model.send(duet1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a269c76",
   "metadata": {},
   "source": [
    "Create alias for D01's instance of torch called `remote_torch1` so we can refer to the local torch as `torch` and any operation we want to do remotely as `remote_torch1`. Remember, the return values from `remote_torch1` are `Pointers`, not the real objects. They mostly act the same when using them with other `Pointers` but you can't mix them with local torch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10b6097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch1 = duet1.torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce3e96",
   "metadata": {},
   "source": [
    "Set arguments for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0564e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a few settings which are from the original MNIST example command-line args\n",
    "args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 1000,\n",
    "    \"epochs\": 14,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec3d20",
   "metadata": {},
   "source": [
    "CUDA check cells below doesn't appear to works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc8ddb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets ask to see if our Data Owner has CUDA\n",
    "#has_cuda = False\n",
    "#has_cuda_ptr = remote_torch1.cuda.is_available()\n",
    "#has_cuda = bool(has_cuda_ptr.get())\n",
    "#print(has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e748b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "# now we can set the seed\n",
    "#remote_torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "#device = remote_torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#print(f\"Data Owner device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1692bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have CUDA lets send our model to the GPU\n",
    "#if has_cuda:\n",
    "    #model.cuda(device)\n",
    "#else:\n",
    "    #model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34b9608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = remote_model1.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cordless-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim1 = remote_torch1.optim.Adam(params=params, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "clinical-cement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.9675072431564331\n",
      "Epoch 1 loss 0.25259271264076233\n",
      "Epoch 2 loss 0.2833402454853058\n",
      "Epoch 3 loss 0.3596494495868683\n",
      "Epoch 4 loss 0.36820387840270996\n",
      "Epoch 5 loss 0.33501142263412476\n",
      "Epoch 6 loss 0.28644120693206787\n",
      "Epoch 7 loss 0.2435450702905655\n",
      "Epoch 8 loss 0.2221793532371521\n",
      "Epoch 9 loss 0.22975605726242065\n",
      "Epoch 10 loss 0.24947024881839752\n",
      "Epoch 11 loss 0.24752941727638245\n",
      "Epoch 12 loss 0.23148126900196075\n",
      "Epoch 13 loss 0.2219582498073578\n",
      "Epoch 14 loss 0.2205892652273178\n",
      "Epoch 15 loss 0.22509416937828064\n",
      "Epoch 16 loss 0.22930310666561127\n",
      "Epoch 17 loss 0.23033839464187622\n",
      "Epoch 18 loss 0.22836017608642578\n",
      "Epoch 19 loss 0.22428017854690552\n",
      "Epoch 20 loss 0.2204708307981491\n",
      "Epoch 21 loss 0.21759475767612457\n",
      "Epoch 22 loss 0.21869152784347534\n",
      "Epoch 23 loss 0.22089259326457977\n",
      "Epoch 24 loss 0.2223421037197113\n"
     ]
    }
   ],
   "source": [
    "iteration = 25\n",
    "losses = train(iteration, remote_model1, remote_torch1, optim1, data1_ptr, target1_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-election",
   "metadata": {},
   "source": [
    "Train on Data Owner 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continental-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model2 = base_model.send(duet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cellular-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch2 = duet2.torch\n",
    "params = remote_model2.parameters()\n",
    "optim2 = remote_torch2.optim.Adam(params=params, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "loose-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.967623233795166\n",
      "Epoch 1 loss 0.25391456484794617\n",
      "Epoch 2 loss 0.28629398345947266\n",
      "Epoch 3 loss 0.36338305473327637\n",
      "Epoch 4 loss 0.37011367082595825\n",
      "Epoch 5 loss 0.33514249324798584\n",
      "Epoch 6 loss 0.28645068407058716\n",
      "Epoch 7 loss 0.24405555427074432\n",
      "Epoch 8 loss 0.22424325346946716\n",
      "Epoch 9 loss 0.23271997272968292\n",
      "Epoch 10 loss 0.25173133611679077\n",
      "Epoch 11 loss 0.24873320758342743\n",
      "Epoch 12 loss 0.23339159786701202\n",
      "Epoch 13 loss 0.22353337705135345\n",
      "Epoch 14 loss 0.2234545797109604\n",
      "Epoch 15 loss 0.226954847574234\n",
      "Epoch 16 loss 0.23202267289161682\n",
      "Epoch 17 loss 0.23258498311042786\n",
      "Epoch 18 loss 0.23067247867584229\n",
      "Epoch 19 loss 0.22616545855998993\n",
      "Epoch 20 loss 0.22213506698608398\n",
      "Epoch 21 loss 0.21967430412769318\n",
      "Epoch 22 loss 0.22062432765960693\n",
      "Epoch 23 loss 0.2231285572052002\n",
      "Epoch 24 loss 0.2244308739900589\n"
     ]
    }
   ],
   "source": [
    "iteration = 25\n",
    "losses = train(iteration, remote_model2, remote_torch2, optim2, data2_ptr, target2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-gravity",
   "metadata": {},
   "source": [
    "### Averaging Model Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-bangladesh",
   "metadata": {},
   "source": [
    "Ideally, there will be a coordinator server with a secure aggreagtor who will get the model updates from different clients and make an aggregation. For the case of simplicity, in this example we will make the Data Sceintist server work as the coordinator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-passage",
   "metadata": {},
   "source": [
    "### Little sanity check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eastern-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model parameters:\n",
      "[Parameter containing:\n",
      "tensor([[-0.1263,  0.0106, -0.1283,  ..., -0.0751, -0.0363,  0.0688],\n",
      "        [-0.0893, -0.1118,  0.0577,  ..., -0.0227,  0.0760, -0.0616],\n",
      "        [-0.1561,  0.0440,  0.0982,  ..., -0.1406, -0.1197,  0.0893],\n",
      "        ...,\n",
      "        [-0.0721, -0.1279,  0.0421,  ..., -0.0668,  0.0589, -0.0801],\n",
      "        [ 0.1059, -0.1079,  0.0716,  ..., -0.0889,  0.0449,  0.1104],\n",
      "        [-0.1188, -0.0803, -0.0919,  ...,  0.0567,  0.0474, -0.0054]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1167,  0.1575, -0.0918,  0.0347,  0.0797, -0.0727,  0.1446, -0.0194,\n",
      "        -0.0313, -0.1159, -0.1392,  0.0880,  0.0081,  0.0422,  0.1128,  0.1071,\n",
      "        -0.0674, -0.1275,  0.0218, -0.0305,  0.1316, -0.1534,  0.0911, -0.1578,\n",
      "         0.1431,  0.0996, -0.0701,  0.0257, -0.0502,  0.1555,  0.1305],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0827,  0.1264,  0.0488,  0.1081, -0.0350, -0.0663,  0.1164,  0.1190,\n",
      "          0.0412, -0.0337,  0.0967,  0.1124, -0.1427,  0.1719,  0.1130,  0.0183,\n",
      "         -0.1024, -0.0453,  0.1788, -0.0897,  0.1592, -0.0935, -0.0352,  0.1078,\n",
      "          0.1324, -0.1511,  0.0777, -0.0939, -0.1611, -0.1391,  0.0834]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0490], requires_grad=True)]\n",
      "\n",
      "Remote model1 parameters:\n",
      "[Parameter containing:\n",
      "tensor([[-0.6818, -0.5457, -0.6829,  ..., -0.0751, -0.0363, -0.4513],\n",
      "        [-0.6459, -0.6684, -0.4989,  ..., -0.5793, -0.4806, -0.6182],\n",
      "        [-0.7127, -0.5126, -0.4585,  ..., -0.6972, -0.6763, -0.4672],\n",
      "        ...,\n",
      "        [-0.1361,  0.0051,  0.2463,  ...,  0.2685,  0.4015,  0.1573],\n",
      "        [ 0.1760,  0.1334,  0.3674,  ...,  0.4384,  0.4327,  0.3927],\n",
      "        [-0.6754, -0.6369, -0.6486,  ..., -0.4999, -0.5092, -0.5617]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.6731, -0.3991, -0.6485, -0.5219, -0.2134, -0.1244, -0.4120, -0.5761,\n",
      "        -0.5867, -0.4162, -0.6958, -0.4686,  0.2587, -0.5144, -0.4438, -0.4495,\n",
      "         0.2097, -0.4207, -0.5348, -0.2746, -0.4262, -0.5177, -0.2549, -0.7144,\n",
      "        -0.4135,  0.4458, -0.6268,  0.3160,  0.1464,  0.4895, -0.4261],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.4733, -0.4303, -0.5078, -0.4486,  0.5210, -0.0042, -0.4402, -0.4376,\n",
      "         -0.5091,  0.5471, -0.4599, -0.4442, -0.1059, -0.3847, -0.4437, -0.5383,\n",
      "         -0.1769,  0.5302, -0.3778,  0.5385, -0.3978,  0.3863,  0.3956, -0.4488,\n",
      "         -0.4242, -0.2016, -0.4790, -0.1806, -0.1007, -0.2352, -0.4732]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.6108], requires_grad=True)]\n",
      "\n",
      "Remote model2 parameters:\n",
      "[Parameter containing:\n",
      "tensor([[-0.6815, -0.5456, -0.6830,  ..., -0.0751, -0.0363,  0.0688],\n",
      "        [-0.6459, -0.6684, -0.4989,  ..., -0.5793, -0.4806, -0.6182],\n",
      "        [-0.7127, -0.5126, -0.4585,  ..., -0.6972, -0.6763, -0.4672],\n",
      "        ...,\n",
      "        [-0.1358,  0.0089,  0.2510,  ...,  0.2675,  0.3831,  0.1096],\n",
      "        [ 0.1746,  0.1396,  0.3737,  ...,  0.4374,  0.3918,  0.3371],\n",
      "        [-0.6754, -0.6369, -0.6486,  ..., -0.4999, -0.5092, -0.5617]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.6731, -0.3991, -0.6485, -0.5219, -0.2148, -0.1291, -0.4120, -0.5761,\n",
      "        -0.5859, -0.4127, -0.6958, -0.4686,  0.2577, -0.5144, -0.4438, -0.4495,\n",
      "         0.2062, -0.4198, -0.5348, -0.2766, -0.4262, -0.5168, -0.2557, -0.7144,\n",
      "        -0.4135,  0.4448, -0.6268,  0.3132,  0.1449,  0.4865, -0.4261],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-4.7322e-01, -4.3025e-01, -5.0781e-01, -4.4856e-01,  5.1728e-01,\n",
      "          3.5433e-04, -4.4024e-01, -4.3761e-01, -5.0658e-01,  5.4685e-01,\n",
      "         -4.5985e-01, -4.4421e-01, -1.0881e-01, -3.8472e-01, -4.4367e-01,\n",
      "         -5.3835e-01, -1.7463e-01,  5.3036e-01, -3.7781e-01,  5.3819e-01,\n",
      "         -3.9775e-01,  3.9432e-01,  4.0397e-01, -4.4881e-01, -4.2424e-01,\n",
      "         -2.0425e-01, -4.7897e-01, -1.7951e-01, -1.0346e-01, -2.3347e-01,\n",
      "         -4.7324e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6102], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param1 = remote_model1.parameters().get(request_block=True)\n",
    "param2 = remote_model2.parameters().get(request_block=True)\n",
    "\n",
    "print(\"Base Model parameters:\")\n",
    "print(base_model.parameters())\n",
    "print()\n",
    "\n",
    "print(\"Remote model1 parameters:\")\n",
    "print(param1)\n",
    "print()\n",
    "\n",
    "print(\"Remote model2 parameters:\")\n",
    "print(param2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-beijing",
   "metadata": {},
   "source": [
    "As you can see, the remote model paramter values are different from the base model paramter values. That means the remote copies of our base model got trained and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afraid-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('layer_1.weight', tensor([[-0.6818, -0.5457, -0.6829,  ..., -0.0751, -0.0363, -0.4513],\n",
      "        [-0.6459, -0.6684, -0.4989,  ..., -0.5793, -0.4806, -0.6182],\n",
      "        [-0.7127, -0.5126, -0.4585,  ..., -0.6972, -0.6763, -0.4672],\n",
      "        ...,\n",
      "        [-0.1361,  0.0051,  0.2463,  ...,  0.2685,  0.4015,  0.1573],\n",
      "        [ 0.1760,  0.1334,  0.3674,  ...,  0.4384,  0.4327,  0.3927],\n",
      "        [-0.6754, -0.6369, -0.6486,  ..., -0.4999, -0.5092, -0.5617]])), ('layer_1.bias', tensor([-0.6731, -0.3991, -0.6485, -0.5219, -0.2134, -0.1244, -0.4120, -0.5761,\n",
      "        -0.5867, -0.4162, -0.6958, -0.4686,  0.2587, -0.5144, -0.4438, -0.4495,\n",
      "         0.2097, -0.4207, -0.5348, -0.2746, -0.4262, -0.5177, -0.2549, -0.7144,\n",
      "        -0.4135,  0.4458, -0.6268,  0.3160,  0.1464,  0.4895, -0.4261])), ('layer_out.weight', tensor([[-0.4733, -0.4303, -0.5078, -0.4486,  0.5210, -0.0042, -0.4402, -0.4376,\n",
      "         -0.5091,  0.5471, -0.4599, -0.4442, -0.1059, -0.3847, -0.4437, -0.5383,\n",
      "         -0.1769,  0.5302, -0.3778,  0.5385, -0.3978,  0.3863,  0.3956, -0.4488,\n",
      "         -0.4242, -0.2016, -0.4790, -0.1806, -0.1007, -0.2352, -0.4732]])), ('layer_out.bias', tensor([-0.6108]))])\n"
     ]
    }
   ],
   "source": [
    "remote_model1_updates = remote_model1.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model1_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "limiting-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('layer_1.weight', tensor([[-0.6815, -0.5456, -0.6830,  ..., -0.0751, -0.0363,  0.0688],\n",
      "        [-0.6459, -0.6684, -0.4989,  ..., -0.5793, -0.4806, -0.6182],\n",
      "        [-0.7127, -0.5126, -0.4585,  ..., -0.6972, -0.6763, -0.4672],\n",
      "        ...,\n",
      "        [-0.1358,  0.0089,  0.2510,  ...,  0.2675,  0.3831,  0.1096],\n",
      "        [ 0.1746,  0.1396,  0.3737,  ...,  0.4374,  0.3918,  0.3371],\n",
      "        [-0.6754, -0.6369, -0.6486,  ..., -0.4999, -0.5092, -0.5617]])), ('layer_1.bias', tensor([-0.6731, -0.3991, -0.6485, -0.5219, -0.2148, -0.1291, -0.4120, -0.5761,\n",
      "        -0.5859, -0.4127, -0.6958, -0.4686,  0.2577, -0.5144, -0.4438, -0.4495,\n",
      "         0.2062, -0.4198, -0.5348, -0.2766, -0.4262, -0.5168, -0.2557, -0.7144,\n",
      "        -0.4135,  0.4448, -0.6268,  0.3132,  0.1449,  0.4865, -0.4261])), ('layer_out.weight', tensor([[-4.7322e-01, -4.3025e-01, -5.0781e-01, -4.4856e-01,  5.1728e-01,\n",
      "          3.5433e-04, -4.4024e-01, -4.3761e-01, -5.0658e-01,  5.4685e-01,\n",
      "         -4.5985e-01, -4.4421e-01, -1.0881e-01, -3.8472e-01, -4.4367e-01,\n",
      "         -5.3835e-01, -1.7463e-01,  5.3036e-01, -3.7781e-01,  5.3819e-01,\n",
      "         -3.9775e-01,  3.9432e-01,  4.0397e-01, -4.4881e-01, -4.2424e-01,\n",
      "         -2.0425e-01, -4.7897e-01, -1.7951e-01, -1.0346e-01, -2.3347e-01,\n",
      "         -4.7324e-01]])), ('layer_out.bias', tensor([-0.6102]))])\n"
     ]
    }
   ],
   "source": [
    "remote_model2_updates = remote_model2.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model2_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "personalized-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-platform",
   "metadata": {},
   "source": [
    "Let's do the aggregation of the weights. In this example, we will just calculate the average of corresponding weights from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "experimental-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('layer_1.weight', tensor([[-0.6817, -0.5456, -0.6830,  ..., -0.0751, -0.0363, -0.1913],\n",
      "        [-0.6459, -0.6684, -0.4989,  ..., -0.5793, -0.4806, -0.6182],\n",
      "        [-0.7127, -0.5126, -0.4585,  ..., -0.6972, -0.6763, -0.4672],\n",
      "        ...,\n",
      "        [-0.1360,  0.0070,  0.2486,  ...,  0.2680,  0.3923,  0.1334],\n",
      "        [ 0.1753,  0.1365,  0.3706,  ...,  0.4379,  0.4122,  0.3649],\n",
      "        [-0.6754, -0.6369, -0.6486,  ..., -0.4999, -0.5092, -0.5617]])), ('layer_1.bias', tensor([-0.6731, -0.3991, -0.6485, -0.5219, -0.2141, -0.1268, -0.4120, -0.5761,\n",
      "        -0.5863, -0.4144, -0.6958, -0.4686,  0.2582, -0.5144, -0.4438, -0.4495,\n",
      "         0.2079, -0.4203, -0.5348, -0.2756, -0.4262, -0.5173, -0.2553, -0.7144,\n",
      "        -0.4135,  0.4453, -0.6268,  0.3146,  0.1456,  0.4880, -0.4261])), ('layer_out.weight', tensor([[-0.4733, -0.4303, -0.5078, -0.4486,  0.5191, -0.0019, -0.4402, -0.4376,\n",
      "         -0.5079,  0.5470, -0.4599, -0.4442, -0.1074, -0.3847, -0.4437, -0.5383,\n",
      "         -0.1758,  0.5303, -0.3778,  0.5384, -0.3978,  0.3903,  0.3998, -0.4488,\n",
      "         -0.4242, -0.2029, -0.4790, -0.1800, -0.1021, -0.2343, -0.4732]])), ('layer_out.bias', tensor([-0.6105]))])\n"
     ]
    }
   ],
   "source": [
    "avg_updates = OrderedDict()\n",
    "avg_updates[\"layer_1.weight\"] = (\n",
    "    remote_model1_updates[\"layer_1.weight\"] + remote_model2_updates[\"layer_1.weight\"]\n",
    ") / 2\n",
    "avg_updates[\"layer_1.bias\"] = (\n",
    "    remote_model1_updates[\"layer_1.bias\"] + remote_model2_updates[\"layer_1.bias\"]\n",
    ") / 2\n",
    "avg_updates[\"layer_out.weight\"] = (\n",
    "    remote_model1_updates[\"layer_out.weight\"] + remote_model2_updates[\"layer_out.weight\"]\n",
    ") / 2\n",
    "avg_updates[\"layer_out.bias\"] = (\n",
    "    remote_model1_updates[\"layer_out.bias\"] + remote_model2_updates[\"layer_out.bias\"]\n",
    ") / 2\n",
    "\n",
    "print(avg_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-scotland",
   "metadata": {},
   "source": [
    "### Load aggregated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hungarian-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exempt-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.load_state_dict(avg_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beautiful-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "del avg_updates, remote_model1_updates, remote_model2_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dec2c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bc64c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_val_0 = pd.read_csv('ETL/X_val_0.csv')\n",
    "df_y_val_0 = pd.read_csv('ETL/y_val_0.csv')\n",
    "X_val_0_np = df_X_val_0.to_numpy()\n",
    "y_val_0_np = df_y_val_0.to_numpy()\n",
    "X_val_0 = th.from_numpy(X_val_0_np).float()\n",
    "y_val_0 = th.from_numpy(y_val_0_np).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "assured-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_val_0)):\n",
    "        sample = X_val_0[i]\n",
    "        y_hat = combined_model(sample)\n",
    "\n",
    "        preds.append(y_hat)\n",
    "preds = [a.squeeze().tolist() for a in preds]\n",
    "preds_exp=np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82690dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Poisson Deviance : 0.34470368907283583\n",
      "Mean Squared Error : 0.059390698372633506\n",
      "R^2 : -0.04993585845490034\n",
      "DescribeResult(nobs=27121, minmax=(0.020573574537936536, 0.49227459518370614), mean=0.08662207216265036, variance=0.0016356821994002462, skewness=1.6160389658242844, kurtosis=4.368956680530511)\n"
     ]
    }
   ],
   "source": [
    "def test_statistics(y_test, y_pred_list_exp):\n",
    "    mpd = mean_poisson_deviance(y_test, y_pred_list_exp)\n",
    "    mse = mean_squared_error(y_test, y_pred_list_exp)\n",
    "    r_square = r2_score(y_test, y_pred_list_exp)\n",
    "    print(\"Mean Poisson Deviance :\",mpd)\n",
    "    print(\"Mean Squared Error :\",mse)\n",
    "    print(\"R^2 :\",r_square)\n",
    "    print(stats.describe(y_pred_list_exp))\n",
    "\n",
    "test_statistics(y_val_0, preds_exp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "charged-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_val_0)):\n",
    "        sample = X_val_0[i]\n",
    "        y_hat = base_model(sample)\n",
    "\n",
    "        preds.append(y_hat)\n",
    "preds = [a.squeeze().tolist() for a in preds]\n",
    "preds_exp=np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c2f059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Poisson Deviance : 1.8362483034975676\n",
      "Mean Squared Error : 0.8924787924057628\n",
      "R^2 : -14.777647219738979\n",
      "DescribeResult(nobs=27121, minmax=(0.7189298303256256, 1.2776400909436074), mean=0.9639654118311258, variance=0.005044648400737673, skewness=0.2569394470817801, kurtosis=-0.12768607416552769)\n"
     ]
    }
   ],
   "source": [
    "test_statistics(y_val_0, preds_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-italy",
   "metadata": {},
   "source": [
    "## Comparison to classical linear regression on centralised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "in_dim = 1\n",
    "out_dim = 1\n",
    "\n",
    "\n",
    "class ClassicalLR(torch.nn.Module):\n",
    "    def __init__(self, torch):\n",
    "        super(ClassicalLR, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "classical_model = ClassicalLR(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(\n",
    "    np.array([5, 15, 25, 35, 45, 55, 60, 65, 75, 85, 95]).reshape(-1, 1)\n",
    ")\n",
    "target = torch.FloatTensor(\n",
    "    np.array([5, 10, 15, 22, 30, 38, 35, 40, 45, 55, 60]).reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_train(iterations, model, torch, optim, data, target, criterion):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_item)\n",
    "\n",
    "        losses.append(loss_item)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = classical_model.parameters()\n",
    "optim = torch.optim.Adam(params=params, lr=0.1)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "losses = classic_train(\n",
    "    iteration, classical_model, torch, optim, data, target, criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = classical_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f22090b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
