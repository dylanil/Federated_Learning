{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earlier-investing",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 1 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sized-session",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "â™«â™«â™« > Duet Client ID: \u001b[1m15dea33d37950ffa541c77f0fd2312f7\u001b[0m\n",
      "\n",
      "â™«â™«â™« > ...waiting for partner to connect...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "C:\\Users\\dylan\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet1 = sy.duet(\"52b35ffe2dd5c09b84d5a1376105e996\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-container",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 2 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-knife",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "â™«â™«â™« > Duet Client ID: \u001b[1m48ef95f5e1e047ff5316399467698eb2\u001b[0m\n",
      "\n",
      "â™«â™«â™« > ...waiting for partner to connect...\n",
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet2 = sy.duet(\"0355643b0357fbf356acabe406031185\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wanted-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 4f3c02da73354c59999192d3781a74eb&gt;</td>\n",
       "      <td>[DO1 training X data]</td>\n",
       "      <td>number of samples and features</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: 8c5b01dc4bf34fb8aa5f12404a2fc7f5&gt;</td>\n",
       "      <td>[DO1 training y data]</td>\n",
       "      <td>number of samples and features</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;UID: 0d042c4a05544d5da25c9303fcf34fe4&gt;</td>\n",
       "      <td>[size of DO1's training data]</td>\n",
       "      <td>size of DO1's training data</td>\n",
       "      <td>&lt;class 'syft.lib.python.Int'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID                           Tags  \\\n",
       "0  <UID: 4f3c02da73354c59999192d3781a74eb>          [DO1 training X data]   \n",
       "1  <UID: 8c5b01dc4bf34fb8aa5f12404a2fc7f5>          [DO1 training y data]   \n",
       "2  <UID: 0d042c4a05544d5da25c9303fcf34fe4>  [size of DO1's training data]   \n",
       "\n",
       "                      Description                    object_type  \n",
       "0  number of samples and features         <class 'torch.Tensor'>  \n",
       "1  number of samples and features         <class 'torch.Tensor'>  \n",
       "2     size of DO1's training data  <class 'syft.lib.python.Int'>  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet1.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "going-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 2501dff885624096a2e9097d9735876d&gt;</td>\n",
       "      <td>[DO2 training X data]</td>\n",
       "      <td>number of samples and features</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: b6c88f867fda4b1484666dbc75151e6c&gt;</td>\n",
       "      <td>[DO2 training y data]</td>\n",
       "      <td>number of samples and features</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;UID: d15b056a2fa74a2b83c3ce9cc0cc1741&gt;</td>\n",
       "      <td>[size of DO2's training data]</td>\n",
       "      <td>size of DO2's training data</td>\n",
       "      <td>&lt;class 'syft.lib.python.Int'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID                           Tags  \\\n",
       "0  <UID: 2501dff885624096a2e9097d9735876d>          [DO2 training X data]   \n",
       "1  <UID: b6c88f867fda4b1484666dbc75151e6c>          [DO2 training y data]   \n",
       "2  <UID: d15b056a2fa74a2b83c3ce9cc0cc1741>  [size of DO2's training data]   \n",
       "\n",
       "                      Description                    object_type  \n",
       "0  number of samples and features         <class 'torch.Tensor'>  \n",
       "1  number of samples and features         <class 'torch.Tensor'>  \n",
       "2     size of DO2's training data  <class 'syft.lib.python.Int'>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet2.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-cradle",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qualified-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x000001F44CFBD430>\n",
      "<syft.proxy.torch.TensorPointer object at 0x000001F44C86C310>\n",
      "<syft.proxy.syft.lib.python.IntPointer object at 0x000001F44C86C9D0>\n",
      "<syft.proxy.torch.TensorPointer object at 0x000001F44C86C7F0>\n",
      "<syft.proxy.torch.TensorPointer object at 0x000001F44C86C3A0>\n",
      "<syft.proxy.syft.lib.python.IntPointer object at 0x000001F44C86CB50>\n"
     ]
    }
   ],
   "source": [
    "data1_ptr = duet1.store[0]\n",
    "target1_ptr = duet1.store[1]\n",
    "train_size_1_ptr = duet1.store[2]\n",
    "\n",
    "data2_ptr = duet2.store[0]\n",
    "target2_ptr = duet2.store[1]\n",
    "train_size_2_ptr = duet2.store[2]\n",
    "\n",
    "print(data1_ptr)\n",
    "print(target1_ptr)\n",
    "print(train_size_1_ptr)\n",
    "print(data2_ptr)\n",
    "print(target2_ptr)\n",
    "print(train_size_2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-savage",
   "metadata": {},
   "source": [
    "### Create Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f979653",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bizarre-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn \n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_poisson_deviance\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "import torch as th\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advised-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 39\n",
    "out_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9f02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        \n",
    "        self.layer_1 = self.torch_ref.nn.Linear(39, 31)\n",
    "        self.layer_out = self.torch_ref.nn.Linear(31, 1)\n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout_1 = self.torch_ref.nn.Dropout(0.12409392594394411)\n",
    "        self.relu = self.torch_ref.nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.dropout_1(self.relu(self.layer_1(inputs)))\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return (x)\n",
    "\n",
    "    def predict(self, test_inputs):\n",
    "        x = self.relu(self.layer_1(test_inputs))\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-factor",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e97835",
   "metadata": {},
   "source": [
    "Set arguments for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0564e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a few settings which are from the original MNIST example command-line args\n",
    "args = {\n",
    "    \"batch_size\": 1000,\n",
    "    \"log_batch_size\":10,\n",
    "    \"test_batch_size\": 1,\n",
    "    \"epochs\": 25,\n",
    "    \"lr\": 6.888528294546944e-05,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"threads\":0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa158eb",
   "metadata": {},
   "source": [
    "##### Custom PyTorch Dataset Class for batch loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb7072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromPointer(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 X_tensorpointer,\n",
    "                 y_tensorpointer,\n",
    "                 datanum_pointer,\n",
    "                 ):\n",
    "        super(DatasetFromPointer, self).__init__()\n",
    "        self.X_tensorpointer = X_tensorpointer\n",
    "        self.y_tensorpointer = y_tensorpointer\n",
    "        self.datanum_pointer = datanum_pointer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = self.X_tensorpointer[index]\n",
    "        target = self.y_tensorpointer[index]\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum_pointer.get(\n",
    "        request_block=True,\n",
    "        reason=\"To write the training loop\",\n",
    "        timeout_secs=30,\n",
    "        delete_obj=False,\n",
    "    )\n",
    "        \n",
    "def batch_idx_fn(batch):\n",
    "    return batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9acccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_1 = DatasetFromPointer(data1_ptr, target1_ptr, train_size_1_ptr)\n",
    "\n",
    "training_data_loader_1 = DataLoader(dataset=train_set_1, \n",
    "                                  num_workers=args[\"threads\"], batch_size=args[\"batch_size\"], shuffle=True,\n",
    "                                  collate_fn=batch_idx_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "077158a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset size is: 244085\n"
     ]
    }
   ],
   "source": [
    "# normally we would not necessarily know the length of a remote dataset so lets ask for it\n",
    "# so we can pass that to our training loop and know when to stop\n",
    "def get_train_length(train_data_ptr):\n",
    "    train_data_length = len(train_data_ptr)\n",
    "    return train_data_length\n",
    "\n",
    "try:\n",
    "    if train_data_length is None:\n",
    "        train_data_length = get_train_length(data1_ptr)\n",
    "except NameError:\n",
    "        train_data_length = get_train_length(data1_ptr)\n",
    "\n",
    "print(f\"Training Dataset size is: {train_data_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e145d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data loader size is: 245\n"
     ]
    }
   ],
   "source": [
    "# normally we would not necessarily know the length of a remote dataset so lets ask for it\n",
    "# so we can pass that to our training loop and know when to stop\n",
    "def get_train_loader_length(training_data_loader):\n",
    "    train_data_loader_length = len(training_data_loader)\n",
    "    return train_data_loader_length\n",
    "\n",
    "try:\n",
    "    if train_data_loader_length is None:\n",
    "        train_data_loader_length = get_train_length(training_data_loader_1)\n",
    "except NameError:\n",
    "        train_data_loader_length = get_train_length(training_data_loader_1)\n",
    "\n",
    "print(f\"Training Data loader size is: {train_data_loader_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62dd21",
   "metadata": {},
   "source": [
    "##### Try different training loop functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c382ab95",
   "metadata": {},
   "source": [
    "Below is a basic loop from an Iris classifier example from an OpenMined course: https://courses.openmined.org/courses/foundations-of-private-computation/5b4beea5-9e95-42a5-9b8e-c5222386314a/2cd76fa7-bfd8-42cf-8913-19b1536ddc87\n",
    "\n",
    "**Also might be worth going through for more examples of how to use Duet!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chinese-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data_ptr)\n",
    "\n",
    "        loss = torch_ref.nn.functional.poisson_nll_loss(output, target_ptr, log_input= True, full= True)   \n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\",\n",
    "            request_block=True,\n",
    "            timeout_secs=5,\n",
    "        )\n",
    "\n",
    "        print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58ef5f",
   "metadata": {},
   "source": [
    "A variant I've come up with which **should** work with batch loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "295b71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_v2(iterations, model, torch_ref, optim, train_loader):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            data_ptr, target_ptr = data[0], data[1]\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            output = model(data_ptr)\n",
    "\n",
    "            loss = torch_ref.nn.functional.poisson_nll_loss(output, target_ptr, log_input= True, full= True)   \n",
    "\n",
    "            loss_item = loss.item()\n",
    "\n",
    "            loss_value = loss_item.get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5,\n",
    "            )\n",
    "\n",
    "            losses.append(loss_value)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optim.step()\n",
    "            \n",
    "        print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0cd29",
   "metadata": {},
   "source": [
    "An adaption of the training loop I initially used in the `0.2.9` use case, but should now work with Duet and batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceecbf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fl(model, torch_ref, optim, train_loader, epochs):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    print(\"Begin training.\")\n",
    "    for e in tqdm(range(1, epochs+1)):\n",
    "\n",
    "        # Training\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_epoch_loss = 0\n",
    "\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            \n",
    "            data_ptr, target_ptr = data[0], data[1]\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            output = model(data_ptr)\n",
    "\n",
    "            loss = torch_ref.nn.functional.poisson_nll_loss(output, target_ptr, log_input= True, full= True)   \n",
    "\n",
    "            loss_item = loss.item()\n",
    "            \n",
    "            loss_value = loss_item.get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5,\n",
    "            )\n",
    "\n",
    "            #print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "            losses.append(loss_value)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optim.step()\n",
    "\n",
    "            train_epoch_loss += loss_value\n",
    "\n",
    "        losses.append(train_epoch_loss/train_data_loader_length)\n",
    "        \n",
    "        print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/train_data_loader_length:.5f}')\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7eb490",
   "metadata": {},
   "source": [
    "Similarly, an adaption of an OpenMined course training loop I found: https://github.com/OpenMined/courses/tree/foundations-of-private-computation/federated-learning/duet_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2799b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MNIST(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length, duet_server):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((train_data_length / args[\"batch_size\"]) + 0.5)\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    if model.is_local:\n",
    "        print(\"Training requires remote model\")\n",
    "        return\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = torch_ref.nn.functional.poisson_nll_loss(output, target_ptr, log_input= True, full= True)   \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = duet_server.python.Float(0)  # create a remote Float we can use for summation\n",
    "        train_loss += loss_item\n",
    "        \n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "        \n",
    "            local_loss = None\n",
    "            \n",
    "            local_loss = loss_item.get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5\n",
    "            )\n",
    "\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break\n",
    "        \n",
    "        if args[\"dry_run\"]:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-guide",
   "metadata": {},
   "source": [
    "#### Send one copy of the model to each data owner or client and train them remotely one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee21bc",
   "metadata": {},
   "source": [
    "Create a local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "proved-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-partner",
   "metadata": {},
   "source": [
    "Send the model to DO1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "convinced-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1 = base_model.send(duet1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a269c76",
   "metadata": {},
   "source": [
    "Create alias for DO1's instance of torch called `remote_torch1` so we can refer to the local torch as `torch` and any operation we want to do remotely as `remote_torch1`. Remember, the return values from `remote_torch1` are `Pointers`, not the real objects. They mostly act the same when using them with other `Pointers` but you can't mix them with local torch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10b6097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch1 = duet1.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc8ddb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# lets ask to see if our Data Owner has CUDA\n",
    "has_cuda = False\n",
    "has_cuda_ptr = remote_torch1.cuda.is_available()\n",
    "has_cuda = bool(has_cuda_ptr.get(\n",
    "    request_block=True,\n",
    "    reason=\"To run test and inference locally\",\n",
    "    timeout_secs=5,  # change to something slower\n",
    "))\n",
    "print(has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e748b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Owner 1 device is cpu\n"
     ]
    }
   ],
   "source": [
    "use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "# now we can set the seed\n",
    "remote_torch1.manual_seed(args[\"seed\"])\n",
    "\n",
    "device = remote_torch1.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"Data Owner 1 device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1692bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    base_model.cuda(device)\n",
    "else:\n",
    "    base_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0eca44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "#train_data_ptr = duet1.store[0]\n",
    "#train_loader_ptr1 = remote_torch1.utils.data.DataLoader(train_dataset_ptr1,**train_kwargs, shuffle=False)\n",
    "#train_loader_ptr1 = remote_torch1.utils.data.DataLoader(data1_ptr,**train_kwargs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34b9608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = remote_model1.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cordless-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim1 = remote_torch1.optim.Adam(params=params, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85978c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler1 = remote_torch1.optim.lr_scheduler.StepLR(optim1, step_size=1, gamma=args[\"gamma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "clinical-cement",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_61604/276473219.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#losses = train(iteration, remote_model1, remote_torch1, optim1, data1_ptr, target1_ptr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremote_model1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremote_torch1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_data_loader_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#losses = train_v3(iteration, remote_model1, remote_torch1, optim1, training_data_loader_1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#losses = train_fl(remote_model1, remote_torch1, optim1, training_data_loader_1, 25)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_61604/3396669489.py\u001b[0m in \u001b[0;36mtrain_v2\u001b[1;34m(iterations, model, torch_ref, optim, train_loader)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mloss_item\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             loss_value = loss_item.get(\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"To evaluate training progress\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mrequest_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\core\\pointer\\pointer.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, request_block, timeout_secs, reason, delete_obj, verbose)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete_obj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelete_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             response_status = self.request(\n\u001b[0m\u001b[0;32m    272\u001b[0m                 \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\core\\pointer\\pointer.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, reason, block, timeout_secs, verbose)\u001b[0m\n\u001b[0;32m    471\u001b[0m                             \u001b[0mreply_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m                         )\n\u001b[1;32m--> 473\u001b[1;33m                         response = self.client.send_immediate_msg_with_reply(\n\u001b[0m\u001b[0;32m    474\u001b[0m                             \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstatus_msg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m                         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\core\\node\\common\\client.py\u001b[0m in \u001b[0;36msend_immediate_msg_with_reply\u001b[1;34m(self, msg, route_index)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigning_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigning_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroutes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroute_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_immediate_msg_with_reply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;31m# check if we have an ExceptionMessage to trigger a local exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\core\\io\\route.py\u001b[0m in \u001b[0;36msend_immediate_msg_with_reply\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSignedImmediateSyftMessageWithReply\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     ) -> SignedImmediateSyftMessageWithoutReply:\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_immediate_msg_with_reply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_object2proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSoloRoute_PB\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\grid\\connections\\webrtc.py\u001b[0m in \u001b[0;36msend_immediate_msg_with_reply\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;31m# properly fix this!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             return validate_type(\n\u001b[1;32m--> 517\u001b[1;33m                 \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_sync_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(future, debug)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_debug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheduled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_when\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m86400\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscheduled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             else None)\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mevent_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\selectors.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\selectors.py\u001b[0m in \u001b[0;36m_select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iteration = 25\n",
    "#losses = train(iteration, remote_model1, remote_torch1, optim1, data1_ptr, target1_ptr)\n",
    "losses = train_v2(iteration, remote_model1, remote_torch1, optim1, training_data_loader_1)\n",
    "#losses = train_fl(remote_model1, remote_torch1, optim1, training_data_loader_1, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9273bed",
   "metadata": {},
   "source": [
    "This is how the MNIST example training loop gets executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f5257fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Epoch: 1\n",
      "> Running train in 245 batches\n",
      "Train Epoch: 1 0 ?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21296/3090281959.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch: {epoch}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# remote training on model with remote_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtrain_MNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremote_model1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremote_torch1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_data_loader_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduet1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# local testing on model with local torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#test_local(model, torch, test_loader, test_data_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21296/2304112436.py\u001b[0m in \u001b[0;36mtrain_MNIST\u001b[1;34m(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length, duet_server)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mlocal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             local_loss = loss_item.get(\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"To evaluate training progress\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mrequest_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\core\\pointer\\pointer.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, request_block, timeout_secs, reason, delete_obj, verbose)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete_obj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelete_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             response_status = self.request(\n\u001b[0m\u001b[0;32m    272\u001b[0m                 \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\core\\pointer\\pointer.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, reason, block, timeout_secs, verbose)\u001b[0m\n\u001b[0;32m    471\u001b[0m                             \u001b[0mreply_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m                         )\n\u001b[1;32m--> 473\u001b[1;33m                         response = self.client.send_immediate_msg_with_reply(\n\u001b[0m\u001b[0;32m    474\u001b[0m                             \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstatus_msg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m                         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\core\\node\\common\\client.py\u001b[0m in \u001b[0;36msend_immediate_msg_with_reply\u001b[1;34m(self, msg, route_index)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigning_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigning_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroutes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroute_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_immediate_msg_with_reply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;31m# check if we have an ExceptionMessage to trigger a local exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\core\\io\\route.py\u001b[0m in \u001b[0;36msend_immediate_msg_with_reply\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSignedImmediateSyftMessageWithReply\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     ) -> SignedImmediateSyftMessageWithoutReply:\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_immediate_msg_with_reply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_object2proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSoloRoute_PB\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\syft\\grid\\connections\\webrtc.py\u001b[0m in \u001b[0;36msend_immediate_msg_with_reply\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;31m# properly fix this!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             return validate_type(\n\u001b[1;32m--> 517\u001b[1;33m                 \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_sync_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(future, debug)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_debug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheduled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_when\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m86400\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscheduled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             else None)\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mevent_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\selectors.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_pysyft\\lib\\selectors.py\u001b[0m in \u001b[0;36m_select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#args[\"dry_run\"] = True  # comment to do a full train\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    # remote training on model with remote_torch\n",
    "    train_MNIST(remote_model1, remote_torch1, training_data_loader_1, optim1, epoch, args, train_data_length, duet1)\n",
    "    # local testing on model with local torch\n",
    "    #test_local(model, torch, test_loader, test_data_length)\n",
    "    #scheduler1.step()\n",
    "    epoch_end = time.time()\n",
    "    print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "    if args[\"dry_run\"]:\n",
    "        break\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa54b4",
   "metadata": {},
   "source": [
    "Training loop from SuperResoulation image example which is where customer Dataset Class came from: https://github.com/OpenMined/PySyft/blob/0.5.0/packages/syft/examples/duet/super_resolution/SuperResolution_Syft_Data_Scientist.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55255731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch_idx 0, loss 1.0572233200073242\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args[\"epochs\"]):\n",
    "    \n",
    "    remote_model1.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_idx, data_pointers in enumerate(training_data_loader_1):\n",
    "\n",
    "        optim1.zero_grad()\n",
    "\n",
    "        data_ptr, target_ptr = data_pointers[0], data_pointers[1]\n",
    "        #data_ptr_reshape = remote_torch.unsqueeze(remote_torch.unsqueeze(data_ptr, 0), 0)\n",
    "        #target_ptr_reshape = remote_torch.unsqueeze(remote_torch.unsqueeze(target_ptr, 0), 0)\n",
    "       \n",
    "        output_ptr = remote_model1(data_ptr)\n",
    "        \n",
    "        loss = remote_torch1.nn.functional.poisson_nll_loss(output_ptr, target_ptr, log_input= True, full= True)   \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optim1.step()\n",
    "\n",
    "        if batch_idx % args[\"log_batch_size\"] == 0:\n",
    "            loss_item = loss.item().get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=3,\n",
    "                delete_obj=False,\n",
    "                verbose=False\n",
    "                )\n",
    "            print(f\"epoch {epoch}, batch_idx {batch_idx}, loss {loss_item}\")\n",
    "\n",
    "        if args[\"dry_run\"]:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80fcf2f",
   "metadata": {},
   "source": [
    "This used the \"basic\" Iris training loop **WITHOUT** batches, but does seem to perform well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2f2c0a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'iteration')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(iteration), losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-election",
   "metadata": {},
   "source": [
    "Train on Data Owner 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "continental-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model2 = base_model.send(duet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cellular-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch2 = duet2.torch\n",
    "params = remote_model2.parameters()\n",
    "optim2 = remote_torch2.optim.Adam(params=params, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "loose-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.866819441318512\n",
      "Epoch 1 loss 0.2198343127965927\n",
      "Epoch 2 loss 0.34583476185798645\n",
      "Epoch 3 loss 0.38866788148880005\n",
      "Epoch 4 loss 0.36773285269737244\n",
      "Epoch 5 loss 0.31869301199913025\n",
      "Epoch 6 loss 0.26128965616226196\n",
      "Epoch 7 loss 0.2231149971485138\n",
      "Epoch 8 loss 0.2449231892824173\n",
      "Epoch 9 loss 0.27834591269493103\n",
      "Epoch 10 loss 0.2464400678873062\n",
      "Epoch 11 loss 0.22350020706653595\n",
      "Epoch 12 loss 0.22525842487812042\n",
      "Epoch 13 loss 0.23436260223388672\n",
      "Epoch 14 loss 0.24199296534061432\n",
      "Epoch 15 loss 0.24152319133281708\n",
      "Epoch 16 loss 0.23684728145599365\n",
      "Epoch 17 loss 0.22808432579040527\n",
      "Epoch 18 loss 0.22101826965808868\n",
      "Epoch 19 loss 0.21924427151679993\n",
      "Epoch 20 loss 0.22245953977108002\n",
      "Epoch 21 loss 0.2273198962211609\n",
      "Epoch 22 loss 0.22881029546260834\n",
      "Epoch 23 loss 0.22510860860347748\n",
      "Epoch 24 loss 0.22009003162384033\n"
     ]
    }
   ],
   "source": [
    "iteration = 25\n",
    "losses = train(iteration, remote_model2, remote_torch2, optim2, data2_ptr, target2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-gravity",
   "metadata": {},
   "source": [
    "### Averaging Model Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-bangladesh",
   "metadata": {},
   "source": [
    "Ideally, there will be a coordinator server with a secure aggreagtor who will get the model updates from different clients and make an aggregation. For the case of simplicity, in this example we will make the Data Sceintist server work as the coordinator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-passage",
   "metadata": {},
   "source": [
    "### Little sanity check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eastern-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model parameters:\n",
      "[Parameter containing:\n",
      "tensor([[-0.0712,  0.1061, -0.0940,  ..., -0.1477,  0.0342,  0.1121],\n",
      "        [ 0.1245, -0.0767, -0.0987,  ...,  0.0216, -0.0068,  0.0889],\n",
      "        [-0.0301, -0.0196, -0.0143,  ..., -0.1531, -0.0409,  0.1513],\n",
      "        ...,\n",
      "        [ 0.0561,  0.0076, -0.1051,  ...,  0.0936,  0.1144,  0.1470],\n",
      "        [ 0.0638,  0.1041, -0.0498,  ...,  0.0147,  0.1587, -0.0028],\n",
      "        [-0.0095, -0.1080,  0.1125,  ..., -0.1189, -0.1485,  0.1548]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1205,  0.0079,  0.0367, -0.0509, -0.0069, -0.1523,  0.1282, -0.1140,\n",
      "         0.0392, -0.1364,  0.1511, -0.0898,  0.0976, -0.1003, -0.1078,  0.0610,\n",
      "         0.1323,  0.0498,  0.0920, -0.1225,  0.1515,  0.1430,  0.1263, -0.0347,\n",
      "         0.0997, -0.0430,  0.1285,  0.1190,  0.1389,  0.1224, -0.1436],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0510,  0.0664, -0.1542, -0.0192, -0.1288,  0.1136, -0.0971,  0.1248,\n",
      "         -0.1040, -0.0646,  0.1185, -0.1536, -0.1034, -0.0861, -0.0826,  0.0778,\n",
      "          0.0772,  0.0193, -0.0852,  0.0540, -0.0353, -0.0659, -0.1753,  0.0733,\n",
      "         -0.1664,  0.1039, -0.0992, -0.0687, -0.1506,  0.0423,  0.0367]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.0597], requires_grad=True)]\n",
      "\n",
      "Remote model1 parameters:\n",
      "[Parameter containing:\n",
      "tensor([[-0.6705, -0.3303, -0.5241,  ..., -0.6079, -0.3797, -0.2847],\n",
      "        [-0.4322, -0.6333, -0.6553,  ..., -0.5350, -0.5634, -0.4677],\n",
      "        [-0.0275, -0.0378,  0.0638,  ..., -0.8276, -0.0713,  0.4437],\n",
      "        ...,\n",
      "        [ 0.0864,  0.1229, -0.0402,  ...,  0.3964,  0.4236,  0.4213],\n",
      "        [-0.4928, -0.4525, -0.6064,  ..., -0.5419, -0.3980, -0.5594],\n",
      "        [-0.0497, -0.1080, -0.2481,  ..., -0.1189, -0.1485,  0.1548]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.5262, -0.5487,  0.1218, -0.4626, -0.3093, -0.7089,  0.0703, -0.6706,\n",
      "         0.2373, -0.5690, -0.4055, -0.5815,  0.3341, -0.4520, -0.0122, -0.4956,\n",
      "        -0.4243, -0.5068,  0.3410, -0.6791, -0.2684,  0.1148,  0.4422, -0.5914,\n",
      "         0.4206, -0.5996,  0.4034,  0.2508,  0.2572, -0.4342, -0.6252],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3320, -0.4902, -0.0399,  0.2196,  0.4279, -0.4430, -0.0025, -0.4319,\n",
      "         -0.1332,  0.4993, -0.4381,  0.3149, -0.1719,  0.1590, -0.1019, -0.4788,\n",
      "         -0.4794, -0.5373, -0.1979, -0.5026,  0.5193, -0.0400, -0.2100, -0.4833,\n",
      "         -0.2589, -0.4527, -0.2317, -0.1294, -0.0629, -0.5143, -0.4621]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.4759], requires_grad=True)]\n",
      "\n",
      "Remote model2 parameters:\n",
      "[Parameter containing:\n",
      "tensor([[-0.6695, -0.3289, -0.5277,  ..., -0.5887, -0.4030, -0.3813],\n",
      "        [-0.4322, -0.6333, -0.6553,  ..., -0.5350, -0.5634, -0.4677],\n",
      "        [-0.0273, -0.0320,  0.0659,  ..., -0.8390, -0.1025,  0.4371],\n",
      "        ...,\n",
      "        [ 0.0813,  0.1252, -0.0410,  ...,  0.3924,  0.4068,  0.4236],\n",
      "        [-0.4928, -0.4525, -0.6064,  ..., -0.5419, -0.3980, -0.5594],\n",
      "        [-0.5131, -0.1080, -0.3874,  ..., -0.1189, -0.1485,  0.1548]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.5267, -0.5487,  0.1208, -0.4643, -0.3141, -0.7089,  0.0686, -0.6706,\n",
      "         0.2371, -0.5729, -0.4055, -0.5863,  0.3319, -0.4578, -0.0125, -0.4956,\n",
      "        -0.4243, -0.5068,  0.3385, -0.6791, -0.2732,  0.1152,  0.4409, -0.5914,\n",
      "         0.4194, -0.5996,  0.4032,  0.2516,  0.2522, -0.4342, -0.6802],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3328, -0.4902, -0.0424,  0.2189,  0.4296, -0.4430, -0.0008, -0.4319,\n",
      "         -0.1350,  0.4970, -0.4381,  0.3171, -0.1710,  0.1660, -0.1035, -0.4788,\n",
      "         -0.4794, -0.5373, -0.1975, -0.5026,  0.5216, -0.0402, -0.2115, -0.4833,\n",
      "         -0.2596, -0.4527, -0.2336, -0.1314, -0.0627, -0.5143, -0.4907]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.4757], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param1 = remote_model1.parameters().get(request_block=True)\n",
    "param2 = remote_model2.parameters().get(request_block=True)\n",
    "\n",
    "print(\"Base Model parameters:\")\n",
    "print(base_model.parameters())\n",
    "print()\n",
    "\n",
    "print(\"Remote model1 parameters:\")\n",
    "print(param1)\n",
    "print()\n",
    "\n",
    "print(\"Remote model2 parameters:\")\n",
    "print(param2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-beijing",
   "metadata": {},
   "source": [
    "As you can see, the remote model paramter values are different from the base model paramter values. That means the remote copies of our base model got trained and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afraid-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('layer_1.weight', tensor([[-0.6705, -0.3303, -0.5241,  ..., -0.6079, -0.3797, -0.2847],\n",
      "        [-0.4322, -0.6333, -0.6553,  ..., -0.5350, -0.5634, -0.4677],\n",
      "        [-0.0275, -0.0378,  0.0638,  ..., -0.8276, -0.0713,  0.4437],\n",
      "        ...,\n",
      "        [ 0.0864,  0.1229, -0.0402,  ...,  0.3964,  0.4236,  0.4213],\n",
      "        [-0.4928, -0.4525, -0.6064,  ..., -0.5419, -0.3980, -0.5594],\n",
      "        [-0.0497, -0.1080, -0.2481,  ..., -0.1189, -0.1485,  0.1548]])), ('layer_1.bias', tensor([-0.5262, -0.5487,  0.1218, -0.4626, -0.3093, -0.7089,  0.0703, -0.6706,\n",
      "         0.2373, -0.5690, -0.4055, -0.5815,  0.3341, -0.4520, -0.0122, -0.4956,\n",
      "        -0.4243, -0.5068,  0.3410, -0.6791, -0.2684,  0.1148,  0.4422, -0.5914,\n",
      "         0.4206, -0.5996,  0.4034,  0.2508,  0.2572, -0.4342, -0.6252])), ('layer_out.weight', tensor([[ 0.3320, -0.4902, -0.0399,  0.2196,  0.4279, -0.4430, -0.0025, -0.4319,\n",
      "         -0.1332,  0.4993, -0.4381,  0.3149, -0.1719,  0.1590, -0.1019, -0.4788,\n",
      "         -0.4794, -0.5373, -0.1979, -0.5026,  0.5193, -0.0400, -0.2100, -0.4833,\n",
      "         -0.2589, -0.4527, -0.2317, -0.1294, -0.0629, -0.5143, -0.4621]])), ('layer_out.bias', tensor([-0.4759]))])\n"
     ]
    }
   ],
   "source": [
    "remote_model1_updates = remote_model1.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model1_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "limiting-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('layer_1.weight', tensor([[-0.6695, -0.3289, -0.5277,  ..., -0.5887, -0.4030, -0.3813],\n",
      "        [-0.4322, -0.6333, -0.6553,  ..., -0.5350, -0.5634, -0.4677],\n",
      "        [-0.0273, -0.0320,  0.0659,  ..., -0.8390, -0.1025,  0.4371],\n",
      "        ...,\n",
      "        [ 0.0813,  0.1252, -0.0410,  ...,  0.3924,  0.4068,  0.4236],\n",
      "        [-0.4928, -0.4525, -0.6064,  ..., -0.5419, -0.3980, -0.5594],\n",
      "        [-0.5131, -0.1080, -0.3874,  ..., -0.1189, -0.1485,  0.1548]])), ('layer_1.bias', tensor([-0.5267, -0.5487,  0.1208, -0.4643, -0.3141, -0.7089,  0.0686, -0.6706,\n",
      "         0.2371, -0.5729, -0.4055, -0.5863,  0.3319, -0.4578, -0.0125, -0.4956,\n",
      "        -0.4243, -0.5068,  0.3385, -0.6791, -0.2732,  0.1152,  0.4409, -0.5914,\n",
      "         0.4194, -0.5996,  0.4032,  0.2516,  0.2522, -0.4342, -0.6802])), ('layer_out.weight', tensor([[ 0.3328, -0.4902, -0.0424,  0.2189,  0.4296, -0.4430, -0.0008, -0.4319,\n",
      "         -0.1350,  0.4970, -0.4381,  0.3171, -0.1710,  0.1660, -0.1035, -0.4788,\n",
      "         -0.4794, -0.5373, -0.1975, -0.5026,  0.5216, -0.0402, -0.2115, -0.4833,\n",
      "         -0.2596, -0.4527, -0.2336, -0.1314, -0.0627, -0.5143, -0.4907]])), ('layer_out.bias', tensor([-0.4757]))])\n"
     ]
    }
   ],
   "source": [
    "remote_model2_updates = remote_model2.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model2_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "personalized-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-platform",
   "metadata": {},
   "source": [
    "Let's do the aggregation of the weights. In this example, we will just calculate the average of corresponding weights from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "experimental-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('layer_1.weight', tensor([[-0.6700, -0.3296, -0.5259,  ..., -0.5983, -0.3913, -0.3330],\n",
      "        [-0.4322, -0.6333, -0.6553,  ..., -0.5350, -0.5634, -0.4677],\n",
      "        [-0.0274, -0.0349,  0.0649,  ..., -0.8333, -0.0869,  0.4404],\n",
      "        ...,\n",
      "        [ 0.0838,  0.1241, -0.0406,  ...,  0.3944,  0.4152,  0.4224],\n",
      "        [-0.4928, -0.4525, -0.6064,  ..., -0.5419, -0.3980, -0.5594],\n",
      "        [-0.2814, -0.1080, -0.3177,  ..., -0.1189, -0.1485,  0.1548]])), ('layer_1.bias', tensor([-0.5264, -0.5487,  0.1213, -0.4635, -0.3117, -0.7089,  0.0695, -0.6706,\n",
      "         0.2372, -0.5710, -0.4055, -0.5839,  0.3330, -0.4549, -0.0124, -0.4956,\n",
      "        -0.4243, -0.5068,  0.3398, -0.6791, -0.2708,  0.1150,  0.4416, -0.5914,\n",
      "         0.4200, -0.5996,  0.4033,  0.2512,  0.2547, -0.4342, -0.6527])), ('layer_out.weight', tensor([[ 0.3324, -0.4902, -0.0411,  0.2192,  0.4288, -0.4430, -0.0017, -0.4319,\n",
      "         -0.1341,  0.4982, -0.4381,  0.3160, -0.1714,  0.1625, -0.1027, -0.4788,\n",
      "         -0.4794, -0.5373, -0.1977, -0.5026,  0.5204, -0.0401, -0.2108, -0.4833,\n",
      "         -0.2593, -0.4527, -0.2326, -0.1304, -0.0628, -0.5143, -0.4764]])), ('layer_out.bias', tensor([-0.4758]))])\n"
     ]
    }
   ],
   "source": [
    "avg_updates = OrderedDict()\n",
    "avg_updates[\"layer_1.weight\"] = (\n",
    "    remote_model1_updates[\"layer_1.weight\"] + remote_model2_updates[\"layer_1.weight\"]\n",
    ") / 2\n",
    "avg_updates[\"layer_1.bias\"] = (\n",
    "    remote_model1_updates[\"layer_1.bias\"] + remote_model2_updates[\"layer_1.bias\"]\n",
    ") / 2\n",
    "avg_updates[\"layer_out.weight\"] = (\n",
    "    remote_model1_updates[\"layer_out.weight\"] + remote_model2_updates[\"layer_out.weight\"]\n",
    ") / 2\n",
    "avg_updates[\"layer_out.bias\"] = (\n",
    "    remote_model1_updates[\"layer_out.bias\"] + remote_model2_updates[\"layer_out.bias\"]\n",
    ") / 2\n",
    "\n",
    "print(avg_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-scotland",
   "metadata": {},
   "source": [
    "### Load aggregated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "hungarian-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "exempt-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.load_state_dict(avg_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "beautiful-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "del avg_updates, remote_model1_updates, remote_model2_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dec2c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bc64c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_val_0 = pd.read_csv('ETL/X_val_0.csv')\n",
    "df_y_val_0 = pd.read_csv('ETL/y_val_0.csv')\n",
    "X_val_0_np = df_X_val_0.to_numpy()\n",
    "y_val_0_np = df_y_val_0.to_numpy()\n",
    "X_val_0 = th.from_numpy(X_val_0_np).float()\n",
    "y_val_0 = th.from_numpy(y_val_0_np).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "assured-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_val_0)):\n",
    "        sample = X_val_0[i]\n",
    "        y_hat = combined_model(sample)\n",
    "\n",
    "        preds.append(y_hat)\n",
    "preds = [a.squeeze().tolist() for a in preds]\n",
    "preds_exp=np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82690dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Poisson Deviance : 0.33151180815157605\n",
      "Mean Squared Error : 0.05777559876995095\n",
      "R^2 : -0.021383390908668254\n",
      "DescribeResult(nobs=27121, minmax=(0.011241376984763856, 0.4387279399098062), mean=0.06384843144156231, variance=0.0012247683010474955, skewness=1.8565834926461535, kurtosis=6.377252593810198)\n"
     ]
    }
   ],
   "source": [
    "def test_statistics(y_test, y_pred_list_exp):\n",
    "    mpd = mean_poisson_deviance(y_test, y_pred_list_exp)\n",
    "    mse = mean_squared_error(y_test, y_pred_list_exp)\n",
    "    r_square = r2_score(y_test, y_pred_list_exp)\n",
    "    print(\"Mean Poisson Deviance :\",mpd)\n",
    "    print(\"Mean Squared Error :\",mse)\n",
    "    print(\"R^2 :\",r_square)\n",
    "    print(stats.describe(y_pred_list_exp))\n",
    "\n",
    "test_statistics(y_val_0, preds_exp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "charged-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_val_0)):\n",
    "        sample = X_val_0[i]\n",
    "        y_hat = base_model(sample)\n",
    "\n",
    "        preds.append(y_hat)\n",
    "preds = [a.squeeze().tolist() for a in preds]\n",
    "preds_exp=np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c2f059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Poisson Deviance : 1.6329049567435172\n",
      "Mean Squared Error : 0.7062302278382026\n",
      "R^2 : -11.485060133149998\n",
      "DescribeResult(nobs=27121, minmax=(0.6151756309625854, 1.1147527252579748), mean=0.85664797196814, variance=0.003856103549277682, skewness=0.15042516022297542, kurtosis=-0.04815565053452486)\n"
     ]
    }
   ],
   "source": [
    "test_statistics(y_val_0, preds_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-italy",
   "metadata": {},
   "source": [
    "## Comparison to classical linear regression on centralised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "external-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "in_dim = 1\n",
    "out_dim = 1\n",
    "\n",
    "\n",
    "class ClassicalLR(torch.nn.Module):\n",
    "    def __init__(self, torch):\n",
    "        super(ClassicalLR, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "classical_model = ClassicalLR(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "featured-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(\n",
    "    np.array([5, 15, 25, 35, 45, 55, 60, 65, 75, 85, 95]).reshape(-1, 1)\n",
    ")\n",
    "target = torch.FloatTensor(\n",
    "    np.array([5, 10, 15, 22, 30, 38, 35, 40, 45, 55, 60]).reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adopted-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_train(iterations, model, torch, optim, data, target, criterion):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_item)\n",
    "\n",
    "        losses.append(loss_item)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "balanced-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = classical_model.parameters()\n",
    "optim = torch.optim.Adam(params=params, lr=0.1)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "technical-gasoline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 187.6728515625\n",
      "Epoch 10 loss 3.2691376209259033\n",
      "Epoch 20 loss 6.015904426574707\n",
      "Epoch 30 loss 6.608091831207275\n",
      "Epoch 40 loss 4.64339542388916\n",
      "Epoch 50 loss 3.185041904449463\n",
      "Epoch 60 loss 3.2361831665039062\n",
      "Epoch 70 loss 3.117515802383423\n",
      "Epoch 80 loss 3.0566627979278564\n",
      "Epoch 90 loss 3.0253264904022217\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "losses = classic_train(\n",
    "    iteration, classical_model, torch, optim, data, target, criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "compound-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "prospective-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 10.919013023376465 Ground Truth: 12.0\n",
      "Prediction: 15.913439750671387 Ground Truth: 15.0\n",
      "Prediction: 20.2835636138916 Ground Truth: 20.0\n",
      "Prediction: 31.52102279663086 Ground Truth: 30.0\n",
      "Prediction: 50.2501220703125 Ground Truth: 50.0\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = classical_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
